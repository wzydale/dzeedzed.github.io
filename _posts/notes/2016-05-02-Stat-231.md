---
layout: post
title: STAT 231 - Statistics
date: 2016-05-02 18:56:00 -0400
categories: notes
--- 

    STAT 231 - Statistics
    Instructor: Surya Banerjee
    Location: DC 1350
    Time: Mondays and Wednesdays 2:30am - 3:50pm
    Tutorials: DC 1351 Mondays 5:30pm - 6:20pm
    Term: Spring 2016
    

## May 2, 2016 - Lecture 1 ##

Email: s22baner@uwaterloo.ca or suryabanerjee@gmail.com

Course Marking Scheme: 3 Tutorial Quizzes (TQ) and 2 Midterms

STAT 231 is the reverse of STAT 230. E.g. We toss a coin 100 times, we get 60 heads. In STAT 230, we calculate the probability of that happening (binomial distribution, 100 and 0.5, P(X=60)) with all the parameters given (P = 0.5 to get a head for a fair coin). In STAT 231, we try to find the parameters by experiments, and try to infer what we can say about the "fairness" of the coin.

MLB: Between 1901-1941, batters with BA .400+: 11. 1941 onwards: 0. Why? Use statistics to find out.

Kansas Weathermen: They are correct about whether it will rain the next day about 85% of the time. Good record, right? However, it only rains about 10% of the time in Kansas. So if I go to the weather broadcasting station and say "no rain tomorrow" and then go home, I will be statistically more accuarate that these meteorologists.

Baseball Pundits: Pundits are right about the outcome of baseball games about 48% of the time. Literally worse than a coin. 

In STAT 231, we learn how to test claims and check for correlation and causation. How can we make the leap from correlation to causation? (Recommended reading: Freakanomics)

<br />

## Introduction to Data Analysis ##

Data can be classified into two categories: numerical and categorical (non-numerical).

**Numerical Data** is either discrete or continuous. Discrete data (e.g. number of accidents) takes integer values, while continuous data (e.g. height, weight) measure non-integer values.

**Categorical Data** is either ordinal (if there's an underlying order, e.g. on a scale from 1 to 10, 1 being least satisfied and 10 being most satisfied) or non-ordinal (no order, e.g. nationality, favorite color).

**Transformation** {x<sub>1</sub>, x<sub>2</sub>,..., x<sub>n</sub>}  
y<sub>i</sub> = f(x<sub>i</sub>) is a transformation.


An affine transformation is a linear transformation: y<sub>i</sub> = ax<sub>i</sub> + b

**Coding** is the conversion of categorical data into numerical data.

<br />

Data Summaries
--------------

We want to extract important information about data.

1. Numerical: come up with numbers that represent different properties of the data set
2. Graphical: graph that tells us the shape of the data set

There are some properties of interest:

+ Centre of the data set -> **Central Tendency**

+ How volatile is the data set -> **Dispersion**

+ If the data set is symmetric -> **Measures of Symmetry**

+ How "fat" the tails of the data set are (i.e. the size of extrema) -> **Kurtosis**

## Measures of Central Tendency

Data set: {y<sub>1</sub>, y<sub>2</sub>,..., y<sub>n</sub>}

**Sample Mean:** 

Property: The sum of the deviations of the observations from the sample mean is 0.

**Geometric Mean**

**Harmonic Mean**

<br />

May 4, 2016 - Lecture 2
---

Lecture notes will be posted every weekend.  
Practice questions (with solutions) will be osted this week. First tutuorial quiz on May 17 (T), 2016 (11:25am).

**Outline**

+ measures of central tendency: medias, quartiles, mode  
+ measures of variability: range, IQR, variance

Sample -> Predictions about the population

Data Summaries
===

+ Centre: CENTRAL TENDENCY  
+ Variability: DISPERSION  
+ Tails are similar: SYMMETRY  
+ Frequency of Extreme Obersevations: KURTOSIS

Numerical and Graphical Summaries
===

{y<sub>1</sub>, y<sub>2</sub>, ... , y<sub>n</sub>}

Sample mean: 1/n sigma y<sub>i</sub>  
Properties: sigma (y<sub>i</sub> - mean) = 0

Also, affine transformation preserves linear combinations (i.e. the arithmetic mean changes accordingly by the affine transformation)

__Median__: the middle most observations  
arrange the data set in ascending order and pick the middle one. e.g. 1, 3, 7, 13, 25. Median is 7.

Median is not too sensitive with extreme values.

__Quartiles__: Q1: lower quartile, Q3: upper quartile

__Percentiles__: Instead of dividing into 4 parts, the data is divided into 100 parts.

Eg. p=0.25, m = (n+1) * p, n is the number of observations

__Mode__: Observation that occurs with the maximum frequency

St.Petersburg's Paradox. We care about averages (expected values), but also risk. Variability is a very important property of a data set. E.g. Country A 0 0 0 1000 and Country B 250 250 250 250
Goalie A 0 6 0 6 0 6 0 6 Goalie B 3 3 3 3 3 3 3 

Measures of Volatility
===

__Range__: Max - Min

__Interquartile Range (IQR)__: IQR = Q3 - Q1

__Sample Variance and Sample Standard Deviation__: 

__Sample Variance__: s<sup>2</sup> = 1/(n-1) sigma (y<sub>i</sub> - y average)<sup>2</sup> is approximatey the average of the squared deviation from the mean

__Standard Deviation__: s = positive square root of s^2, the sample variance

__Mean Absolute Deviation(MAD)__: 1/n sigma abs(y<sub>i</sub> - y average)

Say a data set of x<sub>i</sub> is transformed by an affine transformation y<sub>i</sub> = a + bx<sub>i</sub>. Then s<sup>2</sup> of y = b<sup>2</sup>s<sup>2</sup>. And the standard deviation is multiplied by the absolute value of b.
